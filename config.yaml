# Emergent Communication Training Configuration

training:
  num_episodes: 5000 # Production: 5000
  learning_rate: 0.0003
  max_grad_norm: 1.0
  batch_size: 512
  timesteps_per_episode: 9
  eval_interval: 500 # Log full evaluation stats every N episodes
  device: "auto"  # "cuda", "cpu", or "auto"

agents:
  num_agents: 32
  obs_dim: 4
  msg_dim: 4
  hidden_dim: 64
  latent_dim: 8
  vocab_size: 64
  action_dim: 4

composition:
  use_transformer_decoder: true
  transformer_layers: 2
  transformer_heads: 4
  embedding_dim: 32

task:
  type: "target_seeking"
  num_scouts: 2
  target_range: 5.0
  proximity_weight: 5.0

adversarial:
  enabled: true
  num_adversaries: 4
  strategy: "anti_grounding" # "anti_grounding" or "noise"
  adversarial_weight: 2.0
  curriculum:
    enabled: false
    start_episode: 1000
    ramp_episodes: 2000
    initial_weight: 0.0
    final_weight: 2.0

verification:
  enabled: true
  prob: 0.05 # 5% check probability
  penalty: 0.0 # Disabled penalty
  bonus: 2.0 # Induce leadership with positive reinforcement
  angle_threshold: 45.0 # Tighter threshold for "Truth" (must be well-aligned)

curriculum:
  # Gumbel-Softmax Temperature Annealing
  tau_start: 1.5
  tau_min: 0.05
  anneal_rate: 0.999
  anneal_every: 10
  
  # Entropy Weight
  entropy_weight_start: 0.01
  entropy_weight_end: 0.0
  entropy_decay_episodes: 1500
  
  # Communication Cost
  comm_cost_start: 0.0
  comm_cost_end: 0.1
  comm_cost_ramp_episodes: 3000

  # Stochasticity & Exploration
  exploration_std_start: 0.5
  exploration_std_min: 0.1
  policy_temp_start: 1.0
  policy_temp_min: 0.1
  stochastic_decay_rate: 0.995

topology:
  type: "knearest"
  k_neighbors_start: 8
  k_neighbors_end: 2
  k_decay_episodes: 3000

evolution:
  pbt_enabled: false # Disable PBT for now to focus on adversarial dynamics
  num_species: 4
  selection_interval: 500 # Evolve every N episodes
  mutation_rate: 0.1
  num_elite: 2
  num_replace: 2

environment:
  world_dim: 10
  reward_weight: 2.0
  swarm:
    cohesion_factor: 0.01
    separation_factor: 0.05
    noise_factor: 0.05
    action_scale: 0.1
  oscillatory:
    amplitude: 0.1
    frequencies: [0.05, 0.08, 0.12]

llm:
  provider: "local"  # "local" or "hub"
  local:
    endpoint: "http://localhost:1234/v1/chat/completions"
    model: "google/gemma-3n-e4b"
  hub:
    endpoint: "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-3B-Instruct"
    model: "Qwen/Qwen2.5-3B-Instruct"
