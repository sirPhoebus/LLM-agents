build a prototype AGI-inspired system based on it. From what I understand, the core idea is simulating emergent communication among agents to distill a collective world model from "chaotic" language-like interactions. For a proto AGI, we'll keep it simple: a multi-agent setup in Python where agents observe parts of a shared world, generate messages (as a proxy for generative language), share them, and iteratively refine a collective model through decentralized updates. This mirrors the Generative EmCom framework, using basic neural networks for encoding/decoding and prediction.
To make this runnable right away, I'll structure it as a standalone script. We'll use PyTorch (since it's available in our environment) for the agents' modelsâ€”each agent will have an encoder to generate messages from observations, a decoder to reconstruct from received messages, and a simple predictor for world states. The "world" will be a low-dimensional vector space (e.g., representing object properties), and agents will train via a loss that encourages accurate collective reconstruction (inspired by predictive coding).
We'll simulate 3 agents for starters, with training over episodes. No external dependencies beyond torch and numpy (both available). Run this in a Python environment with those libs.